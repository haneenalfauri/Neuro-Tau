{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vavSgueUQdrJ"
      },
      "source": [
        "# Dataset Merge, Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un0M706HIyep",
        "outputId": "e9cc2a3b-371d-4526-8e39-ab1011a20bb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.neighbors import KernelDensity\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.formula.api as smf\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers, optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l1\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "drive.mount('/content/gdrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "tgznoADmKWJP",
        "outputId": "d2c6372d-3a6c-4cc6-a096-99060bb8df1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-a24c889f4393>:7: DtypeWarning: Columns (19,20,21,50,51,104,105,106) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  ADNI_Merge= pd.read_csv(ADNI_Merge_DIR)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\noutput = pd.DataFrame({'Id': test_df['Id'], 'target': predictions})\\n\\npath_in_google_drive = '/content/gdrive/MyDrive/AP 3/submission.csv'\\n\\n\\noutput.to_csv(path_in_google_drive, index=False)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "Tau_DIR = '/content/gdrive/MyDrive/Neuro_Tau/UCBERKELEY_TAUPVC_6MM_14Feb2024.csv'\n",
        "AMY_DIR = '/content/gdrive/MyDrive/Neuro_Tau/UCBERKELEY_AMY_6MM_17Feb2024.csv'\n",
        "ADNI_Merge_DIR = '/content/gdrive/MyDrive/Neuro_Tau/ADNIMERGE_17Feb2024.csv'\n",
        "\n",
        "Tau= pd.read_csv(Tau_DIR)\n",
        "AMY= pd.read_csv(AMY_DIR)\n",
        "ADNI_Merge= pd.read_csv(ADNI_Merge_DIR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPhRtedoV9A6"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93LKBGxAOqSF",
        "outputId": "4ce5c5a5-05c0-44d5-952c-05323a296ce9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "904\n",
            "(1534, 334)\n",
            "1739\n",
            "(3777, 343)\n",
            "2430\n",
            "(16421, 116)\n",
            "Number of unique RID longitudinal data: 402\n",
            "(1032, 334)\n",
            "(1032, 125)\n",
            "(1032, 129)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-4133a5685e04>:89: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ADNI_Merge['EXAMDATE'] = pd.to_datetime(ADNI_Merge['EXAMDATE'])\n",
            "<ipython-input-39-4133a5685e04>:93: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  ADNI_Merge['EXAMDATE_YEAR'] = ADNI_Merge['EXAMDATE'].dt.year\n"
          ]
        }
      ],
      "source": [
        "unique_rid_count = Tau['RID'].nunique()\n",
        "print(unique_rid_count)\n",
        "\n",
        "print (Tau.shape)\n",
        "\n",
        "\n",
        "AMY_1 = AMY\n",
        "unique_rid_count_AMY_1 = AMY_1['RID'].nunique()\n",
        "print(unique_rid_count_AMY_1)\n",
        "\n",
        "print (AMY_1.shape)\n",
        "\n",
        "\n",
        "DEMO_1 = ADNI_Merge\n",
        "unique_rid_count_DEMO_1 = DEMO_1['RID'].nunique()\n",
        "print(unique_rid_count_DEMO_1)\n",
        "\n",
        "print (DEMO_1.shape)\n",
        "\n",
        "# ******\\\\\\\\\\\\IDENTIFY LONGITUDINAL DATA BASED ON RID DUPLICATES = TWO TIME POINTS FOR SAME PT *******//////////#\n",
        "\n",
        "# Identify all duplicate values in column RID (indicate longitudinal data)\n",
        "# `keep=False` marks all duplicates as True\n",
        "duplicates = Tau.duplicated('RID', keep=False)\n",
        "\n",
        "# Filter the DataFrame to include only duplicates of RID\n",
        "filtered_Tau = Tau[duplicates]\n",
        "unique_rid_count = filtered_Tau['RID'].nunique()\n",
        "print(f\"Number of unique RID longitudinal data: {unique_rid_count}\")\n",
        "print(filtered_Tau.shape)\n",
        "\n",
        "\n",
        "\n",
        "# ******\\\\\\\\\\\\FILTER OUT UNEEDED COLUMNS, KEEP ROI *******//////////#\n",
        "\n",
        "# Keep RID , SCANDATE columns\n",
        "specific_indexes_to_keep = [1, 5]\n",
        "columns = filtered_Tau.columns.tolist()\n",
        "\n",
        "# Keep columns by specified indexes\n",
        "specific_columns_to_keep = [columns[i] for i in specific_indexes_to_keep]\n",
        "\n",
        "# Filter columns after index 5 to keep only those containing 'ctx'\n",
        "columns_after_index_0_with_ctx = [col for col in columns if 'CTX' in col]\n",
        "\n",
        "words = ['AMYGDALA', 'ACCUMBENS', 'CAUDATE', 'HIPPOCAMPUS', 'PALLIDUM', 'PUTAMEN', 'THALAMUS']\n",
        "Specific_columns = [col for col in columns if any(word in col for word in words)]\n",
        "columns_to_keep = specific_columns_to_keep + columns_after_index_0_with_ctx+ Specific_columns\n",
        "\n",
        "# Select only the columns to keep in the DataFrame\n",
        "Remaining_columns = filtered_Tau[columns_to_keep]\n",
        "\n",
        "#Filter out all volume columns but leave SUVR and first few Identifier rows\n",
        "columns_to_drop1 = [col for col in Remaining_columns.columns if \"VOLUME\" in col.upper()]\n",
        "Remaining_columns = Remaining_columns.drop(columns=columns_to_drop1)\n",
        "\n",
        "#print head of remaining_col\n",
        "Remaining_columns.head()\n",
        "\n",
        "print(Remaining_columns.shape)\n",
        "\n",
        "\n",
        "\n",
        "# ******\\\\\\\\\\\\EXTRACT PT DEMOGRAPHIC FROM ADNIMERGE *******//////////#\n",
        "\n",
        "#ADNI MERGE\n",
        "#read ADNIMERGE columns 'PTGENDER' and 'APOE4' and insert them into tau data for matching 'RID's\n",
        "# (Use low_memory=False to avoid error due to mixed type of data)\n",
        "Tau_Data=Remaining_columns\n",
        "ADNI_Merge = ADNI_Merge\n",
        "\n",
        "# Drop duplicates in csv1 to ensure each 'RID' only has one set of values for 'PTGENDER' and 'APOE4'\n",
        "ADNI_Merge = ADNI_Merge.drop_duplicates(subset='RID')\n",
        "\n",
        "# Map 'PTGENDER' and 'APOE4'based on 'RID'\n",
        "Tau_Demographics = Tau_Data.merge(ADNI_Merge[['RID', 'PTGENDER','DX_bl', 'APOE4']], on='RID', how='left')\n",
        "\n",
        "# ******\\\\\\\\\\\\EXTRACT PT AGE BASED ON THE REPORTED AGE IN ADNIMERGE + TIME DIFFERENCE OF SCANDATE AND EXAMDATE(age reported date) *******//////////#\n",
        "#For each RID in Tau_Demographics  matching RID in ADNI_Merge ,\n",
        "#find the row that has the year of EXAMDATE of adnimerge to be matching SCANDATE Tau_Demographics\n",
        "#create latest_ages is a dictionary mapping each RID to the latest AGE from the ADNI_Merge dataset. This age is then added to the Tau_Demographics DataFrame.\n",
        "#Then, year_difference is calculated as the difference between the SCANDATE_YEAR in Tau_Demographics and the latest EXAMDATE_YEAR in ADNI_Merge.\n",
        "#This difference is used to adjust the age accordingly. If there's no matching RID from ADNI_Merge in Tau_Demographics, the age is set to 0.\n",
        "\n",
        "# Convert to datetime\n",
        "Tau_Demographics['SCANDATE'] = pd.to_datetime(Tau_Demographics['SCANDATE'])\n",
        "ADNI_Merge['EXAMDATE'] = pd.to_datetime(ADNI_Merge['EXAMDATE'])\n",
        "\n",
        "# Extract years\n",
        "Tau_Demographics['SCANDATE_YEAR'] = Tau_Demographics['SCANDATE'].dt.year\n",
        "ADNI_Merge['EXAMDATE_YEAR'] = ADNI_Merge['EXAMDATE'].dt.year\n",
        "\n",
        "# Get the latest age and examdate year for each RID in ADNI_Merge\n",
        "latest_exam_info = ADNI_Merge.sort_values('EXAMDATE').groupby('RID').agg({'AGE': 'last', 'EXAMDATE_YEAR': 'last'}).reset_index()\n",
        "\n",
        "# Merge the latest exam information with Tau_Demographics based on RID\n",
        "Tau_Demographics = Tau_Demographics.merge(latest_exam_info, on='RID', how='left', suffixes=('', '_ADNI'))\n",
        "\n",
        "# Calculate the age at SCANDATE for each RID in Tau_Demographics\n",
        "Tau_Demographics['AGE_AT_SCANDATE'] = Tau_Demographics['AGE'] + (Tau_Demographics['SCANDATE_YEAR'] - Tau_Demographics['EXAMDATE_YEAR'])\n",
        "\n",
        "# Replace NaN values in the 'AGE_AT_SCANDATE' column with 0 (where no matching RID was found)\n",
        "Tau_Demographics['AGE_AT_SCANDATE'] = Tau_Demographics['AGE_AT_SCANDATE'].fillna(0)\n",
        "\n",
        "# Drop the extra columns that were used for calculations\n",
        "Tau_Demographics.drop(['SCANDATE_YEAR', 'EXAMDATE_YEAR', 'AGE'], axis=1, inplace=True)\n",
        "\n",
        "# Rename the AGE_AT_SCANDATE column back to AGE\n",
        "Tau_Demographics.rename(columns={'AGE_AT_SCANDATE': 'AGE'}, inplace=True)\n",
        "\n",
        "Tau_Demographics.head()\n",
        "print(Tau_Demographics.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpLf8haWQYDu",
        "outputId": "0187d2ca-167d-41c1-b50f-0ccc3f3b8f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Subcortical featues  6\n",
            "Number of Cotical featues  34\n",
            "Length of tau features with AMY 160\n",
            "(1032, 166)\n",
            "Total number of NaN values in the DataFrame: 0\n",
            "Number of unique RID (longitudinal data after merging + amy-tau merge): 263\n",
            "number of (datapoints , features) (588, 166)\n",
            "Total number of NaN values in the DataFrame: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-374781cc6ab2>:102: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  Remaining_columns['SCANDATE'] = pd.to_datetime(Remaining_columns['SCANDATE'], format='%Y-%m-%d')\n"
          ]
        }
      ],
      "source": [
        "# ******\\\\\\\\\\\\COPY AMYLOID INFO into TAU for specific ROI regions*******//////////#\n",
        "\n",
        "\n",
        "tau_df = Tau_Demographics\n",
        "amy_df = AMY\n",
        "#print(\"1\")\n",
        "#Convert 'SCANDATE' in tau_df and corresponding date column in amy_df to datetime\n",
        "tau_df['SCANDATE'] = pd.to_datetime(tau_df['SCANDATE'], format='%Y-%m-%d')\n",
        "#print(\"2\")\n",
        "amy_df['SCANDATE'] = pd.to_datetime(amy_df['SCANDATE'], format='%Y-%m-%d')\n",
        "#print(\"3\")\n",
        "# Extract years from 'SCANDATE'\n",
        "tau_df['YEAR'] = tau_df['SCANDATE'].dt.year\n",
        "amy_df['YEAR'] = amy_df['SCANDATE'].dt.year\n",
        "\n",
        "#Rename AMY data to avoid confusion with Tau\n",
        "exceptions = ['RID', 'SCANDATE', 'YEAR']  # Add or remove based on your actual data\n",
        "\n",
        "# Rename columns by appending '_AMY' to each column name, except for the exceptions\n",
        "columns_to_rename = {col: col + '_AMY' if col not in exceptions else col for col in amy_df.columns}\n",
        "amy_df.rename(columns=columns_to_rename, inplace=True)\n",
        "\n",
        "\n",
        "# Define the list of specific words to look for in column names RIGH T_X        LEF T_X\n",
        "# remove 'T_ACCUMBENS', to remove NA_LEFT AND NA right region\n",
        "words1 = [  'T_CAUDATE', 'T_HIPPOCAMPUS', 'T_PALLIDUM', 'T_PUTAMEN', 'T_THALAMUS', 'T_AMYGDALA']\n",
        "\n",
        "words2=['H_ENTORHINAL',  'H_BANKSSTS', 'H_CAUDALANTERIORCINGULATE', 'H_CAUDALMIDDLEFRONTAL', 'H_CUNEUS', 'H_FRONTALPOLE', 'H_FUSIFORM', 'H_INFERIORPARIETAL', 'H_INFERIORTEMPORAL', 'H_INSULA',\n",
        " 'H_ISTHMUSCINGULATE', 'H_LATERALOCCIPITAL', 'H_LATERALORBITOFRONTAL', 'H_LINGUAL', 'H_MEDIALORBITOFRONTAL', 'H_MIDDLETEMPORAL', 'H_PARACENTRAL', 'H_PARAHIPPOCAMPAL', 'H_PARSOPERCULARIS', 'H_PARSORBITALIS', 'H_PARSTRIANGULARIS', 'H_PERICALCARINE',\n",
        " 'H_POSTCENTRAL', 'H_POSTERIORCINGULATE', 'H_PRECENTRAL', 'H_PRECUNEUS', 'H_ROSTRALANTERIORCINGULATE', 'H_ROSTRALMIDDLEFRONTAL', 'H_SUPERIORFRONTAL',\n",
        " 'H_SUPERIORPARIETAL', 'H_SUPERIORTEMPORAL', 'H_SUPRAMARGINAL', 'H_TEMPORALPOLE', 'H_TRANSVERSETEMPORAL']\n",
        "\n",
        "print(\"Number of Subcortical featues \",len(words1))\n",
        "print(\"Number of Cotical featues \",len(words2))\n",
        "\n",
        "# 164 = 2 (left right) x 41 region x 2 (amy tau)\n",
        "\n",
        "amy_df.drop('SCANDATE', axis=1, inplace=True)\n",
        "# Perform the merge including all columns for further filtering\n",
        "tau_df = pd.merge(tau_df, amy_df, on=['RID', 'YEAR'], how='left')\n",
        "# Filter columns based on criteria:\n",
        "# - Includes 'CTX' but not 'VOLUME'\n",
        "# - Includes any of the specific brain region names but not 'VOLUME'\n",
        "#columns_to_include = [col for col in tau_df.columns if ('CTX' in col or any(word in col for word in words)) and 'VOLUME' not in col  ]\n",
        "columns_to_include = []\n",
        "for col in tau_df.columns:\n",
        "  if 'CTX' in col and 'VOLUME' not in col  and any( w in col for w in words2):\n",
        "    columns_to_include.append(col)\n",
        "\n",
        "    #print(col)\n",
        "  elif 'VOLUME' not in col  and any( w in col for w in words1):\n",
        "    columns_to_include.append(col)\n",
        "    #print(col)\n",
        "\n",
        "\n",
        "print(\"Length of tau features with AMY\",len(columns_to_include))\n",
        "\n",
        "\n",
        "# Make sure to include 'RID' and 'SCANDATE' for identification ,\n",
        "columns_to_include = ['RID', 'SCANDATE','PTGENDER','DX_bl','AGE','APOE4'] + columns_to_include\n",
        "\n",
        "# Create a new DataFrame with the filtered columns\n",
        "filtered_df = tau_df[columns_to_include]\n",
        "\n",
        "filtered_df.head()\n",
        "\n",
        "print(filtered_df.shape)\n",
        "\n",
        "\n",
        "# Get the number of NaN values in each column\n",
        "\n",
        "nan_counts_per_column = filtered_df.isna().sum()\n",
        "\n",
        "# Sum these counts to get the total number of NaN values in the DataFrame\n",
        "total_nan_count = nan_counts_per_column.sum()\n",
        "\n",
        "# Print the result\n",
        "#print(\"Total number of NaN values in the DataFrame:\", total_nan_count)\n",
        "\n",
        "#Drop rows of missing data\n",
        "Remaining_columns_cleaned = filtered_df.dropna()\n",
        "nan_counts_per_column = Remaining_columns_cleaned.isna().sum()\n",
        "print(\"Total number of NaN values in the DataFrame:\", nan_counts_per_column.sum())\n",
        "\n",
        "\n",
        "# Identify all duplicate values in column RID (indicate longitudinal data)\n",
        "# `keep=False` marks all duplicates as True\n",
        "duplicates = Remaining_columns_cleaned.duplicated('RID', keep=False)\n",
        "# Filter the DataFrame to include only duplicates of RID\n",
        "filtered_df = Remaining_columns_cleaned[duplicates]\n",
        "unique_rid_count = filtered_df['RID'].nunique()\n",
        "print(f\"Number of unique RID (longitudinal data after merging + amy-tau merge): {unique_rid_count}\")\n",
        "\n",
        "print(\"number of (datapoints , features)\",filtered_df.shape)\n",
        "\n",
        "\n",
        "# Deal with SCANDATE , find t and t+1 and t+2 for all RID, start by converting \"SCANDATE\" to datetime format then sort by RID and Scandate\n",
        "\n",
        "Remaining_columns=filtered_df\n",
        "# Convert \"SCANDATE\" to datetime format\n",
        "Remaining_columns['SCANDATE'] = pd.to_datetime(Remaining_columns['SCANDATE'], format='%Y-%m-%d')\n",
        "\n",
        "# Sort the DataFrame by \"RID\" and \"SCANDATE\" to ensure chronological order within each RID\n",
        "Remaining_columns = Remaining_columns.sort_values(by=['RID', 'SCANDATE'])\n",
        "\n",
        "# Calculate the time difference for each \"RID\" compared to the previous row within the same RID\n",
        "Remaining_columns['Time_Difference'] = Remaining_columns.groupby('RID')['SCANDATE'].diff()\n",
        "\n",
        "# Fill NaT values with 0 days to handle the first occurrence of each RID with no prior date\n",
        "Remaining_columns['Time_Difference'] = Remaining_columns['Time_Difference'].fillna(pd.Timedelta(days=0))\n",
        "\n",
        "nan_counts_per_column = Remaining_columns.isna().sum()\n",
        "print(\"Total number of NaN values in the DataFrame:\", nan_counts_per_column.sum())\n",
        "\n",
        "\n",
        "Dataset=Remaining_columns\n",
        "#Binary encode gender\n",
        "Dataset['PTGENDER'] = Dataset['PTGENDER'].replace({'Female': 0, 'Male': 1})\n",
        "\n",
        "# one hot vector for diagnosis\n",
        "encoder = OneHotEncoder(sparse_output=False)  # Use sparse=False to return a 2D array\n",
        "DX_bl_encoded = encoder.fit_transform(Dataset[['DX_bl']])\n",
        "\n",
        "# The encoded features are now in a numpy array. To add them back into a DataFrame:\n",
        "encoded_data = pd.DataFrame(DX_bl_encoded, columns=encoder.get_feature_names_out(['DX_bl']))\n",
        "Dataset_reset = Dataset.reset_index(drop=True)\n",
        "Dataset_final = pd.concat([Dataset_reset, encoded_data], axis=1)\n",
        "\n",
        "\n",
        "\n",
        "Dataset_final.drop('SCANDATE', axis=1, inplace=True)\n",
        "#Dataset_final.drop('DX_bl', axis=1, inplace=True)\n",
        "#Dataset_final.head()\n",
        "\n",
        "\n",
        "Dataset_final.head()\n",
        "\n",
        "# check which RIDs was droped due to insufficiant amyloid info\n",
        "\n",
        "set_tau = set(filtered_Tau['RID'])\n",
        "set_df = set(Dataset_final['RID'])\n",
        "\n",
        "unique_RIDs = set_tau - set_df\n",
        "\n",
        "unique_RIDs_df = pd.DataFrame({'RID': list(unique_RIDs)})\n",
        "\n",
        "# Display the DataFrame of unique RIDs\n",
        "#print(unique_RIDs_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IxA2PsT_jpf"
      },
      "outputs": [],
      "source": [
        "def remove_Amy(data):\n",
        "  cols_to_drop = [col for col in data.columns if col.endswith('_AMY')]\n",
        "  data = data.drop(columns=cols_to_drop)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raUred_cp-ju"
      },
      "outputs": [],
      "source": [
        "Dataset_final=remove_Amy(Dataset_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDmfzuwhQyDx"
      },
      "source": [
        "# Dataset Stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb2MBODnuera"
      },
      "outputs": [],
      "source": [
        "Dataset_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tabulate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlGCXmi79upu",
        "outputId": "8ce07d57-a417-45f4-bdee-47e0f7a47706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.9.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = Dataset_final[Dataset_final['DX_bl'] == 'CN']\n",
        "df_filtered.head()"
      ],
      "metadata": {
        "id": "KffXRnQ_AzFH",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Noise Analysis per region\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "selected_columns = df_filtered.iloc[:, 6:-7]\n",
        "\n",
        "\n",
        "def percentage_points_outside_margin(column):\n",
        "    mean = column.mean()\n",
        "    margin = 0.1 * mean\n",
        "    lower_bound = mean - margin\n",
        "    upper_bound = mean + margin\n",
        "    outside_margin = column[(column < lower_bound) | (column > upper_bound)]\n",
        "    percentage_outside = (len(outside_margin) / len(column)) * 100\n",
        "    return percentage_outside\n",
        "\n",
        "# List to hold results\n",
        "results = []\n",
        "\n",
        "for col in selected_columns.columns:\n",
        "    percentage_outside = percentage_points_outside_margin(selected_columns[col])\n",
        "    results.append([col, percentage_outside])\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['Column', 'Percentage Outside Margin'])\n",
        "\n",
        "print(tabulate(results_df, headers='keys', tablefmt='fancy_grid', showindex=False))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2KalXME8ONg",
        "outputId": "6a01cce3-1e0e-4729-b817-6c56456a33f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "╒══════════════════════════════════════╤═════════════════════════════╕\n",
            "│ Column                               │   Percentage Outside Margin │\n",
            "╞══════════════════════════════════════╪═════════════════════════════╡\n",
            "│ CTX_LH_BANKSSTS_SUVR                 │                     52.4096 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_CAUDALANTERIORCINGULATE_SUVR  │                     37.9518 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_CAUDALMIDDLEFRONTAL_SUVR      │                     33.7349 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_CUNEUS_SUVR                   │                     44.5783 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_ENTORHINAL_SUVR               │                     59.6386 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_FRONTALPOLE_SUVR              │                     50      │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_FUSIFORM_SUVR                 │                     42.7711 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_INFERIORPARIETAL_SUVR         │                     39.759  │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_INFERIORTEMPORAL_SUVR         │                     46.988  │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_INSULA_SUVR                   │                     33.7349 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_ISTHMUSCINGULATE_SUVR         │                     41.5663 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_LATERALOCCIPITAL_SUVR         │                     42.1687 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_LATERALORBITOFRONTAL_SUVR     │                     30.1205 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_LINGUAL_SUVR                  │                     32.5301 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_MEDIALORBITOFRONTAL_SUVR      │                     39.759  │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_MIDDLETEMPORAL_SUVR           │                     46.988  │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_PARACENTRAL_SUVR              │                     33.1325 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_PARAHIPPOCAMPAL_SUVR          │                     53.6145 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_PARSOPERCULARIS_SUVR          │                     31.3253 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_PARSORBITALIS_SUVR            │                     40.9639 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_PARSTRIANGULARIS_SUVR         │                     32.5301 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_PERICALCARINE_SUVR            │                     54.2169 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_POSTCENTRAL_SUVR              │                     30.1205 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_POSTERIORCINGULATE_SUVR       │                     39.1566 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_PRECENTRAL_SUVR               │                     27.7108 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_PRECUNEUS_SUVR                │                     35.5422 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_ROSTRALANTERIORCINGULATE_SUVR │                     27.7108 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_ROSTRALMIDDLEFRONTAL_SUVR     │                     37.3494 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_SUPERIORFRONTAL_SUVR          │                     27.7108 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_SUPERIORPARIETAL_SUVR         │                     39.759  │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_SUPERIORTEMPORAL_SUVR         │                     31.9277 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_SUPRAMARGINAL_SUVR            │                     34.9398 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_TEMPORALPOLE_SUVR             │                     53.012  │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_LH_TRANSVERSETEMPORAL_SUVR       │                     48.1928 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_BANKSSTS_SUVR                 │                     50      │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_CAUDALANTERIORCINGULATE_SUVR  │                     39.1566 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_CAUDALMIDDLEFRONTAL_SUVR      │                     34.3373 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_CUNEUS_SUVR                   │                     44.5783 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_ENTORHINAL_SUVR               │                     63.253  │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_FRONTALPOLE_SUVR              │                     43.3735 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_FUSIFORM_SUVR                 │                     41.5663 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_INFERIORPARIETAL_SUVR         │                     40.3614 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_INFERIORTEMPORAL_SUVR         │                     43.9759 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_INSULA_SUVR                   │                     34.3373 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_ISTHMUSCINGULATE_SUVR         │                     37.9518 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_LATERALOCCIPITAL_SUVR         │                     34.3373 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_LATERALORBITOFRONTAL_SUVR     │                     33.7349 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_LINGUAL_SUVR                  │                     37.3494 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_MEDIALORBITOFRONTAL_SUVR      │                     40.9639 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_MIDDLETEMPORAL_SUVR           │                     42.7711 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_PARACENTRAL_SUVR              │                     31.9277 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_PARAHIPPOCAMPAL_SUVR          │                     54.8193 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_PARSOPERCULARIS_SUVR          │                     31.9277 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_PARSORBITALIS_SUVR            │                     37.9518 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_PARSTRIANGULARIS_SUVR         │                     33.1325 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_PERICALCARINE_SUVR            │                     54.8193 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_POSTCENTRAL_SUVR              │                     24.6988 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_POSTERIORCINGULATE_SUVR       │                     42.7711 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_PRECENTRAL_SUVR               │                     28.9157 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_PRECUNEUS_SUVR                │                     36.1446 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_ROSTRALANTERIORCINGULATE_SUVR │                     34.3373 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_ROSTRALMIDDLEFRONTAL_SUVR     │                     38.5542 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_SUPERIORFRONTAL_SUVR          │                     31.3253 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_SUPERIORPARIETAL_SUVR         │                     40.3614 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_SUPERIORTEMPORAL_SUVR         │                     36.1446 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_SUPRAMARGINAL_SUVR            │                     30.1205 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_TEMPORALPOLE_SUVR             │                     48.1928 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ CTX_RH_TRANSVERSETEMPORAL_SUVR       │                     50.6024 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ LEFT_AMYGDALA_SUVR                   │                     51.2048 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ LEFT_CAUDATE_SUVR                    │                     60.8434 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ LEFT_HIPPOCAMPUS_SUVR                │                     46.988  │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ LEFT_PALLIDUM_SUVR                   │                     50.6024 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ LEFT_PUTAMEN_SUVR                    │                     50      │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ LEFT_THALAMUS_PROPER_SUVR            │                     29.5181 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ RIGHT_AMYGDALA_SUVR                  │                     51.8072 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ RIGHT_CAUDATE_SUVR                   │                     60.241  │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ RIGHT_HIPPOCAMPUS_SUVR               │                     56.0241 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ RIGHT_PALLIDUM_SUVR                  │                     53.6145 │\n",
            "├──────────────────────────────────────┼─────────────────────────────┤\n",
            "│ RIGHT_PUTAMEN_SUVR                   │                     54.8193 │\n",
            "╘══════════════════════════════════════╧═════════════════════════════╛\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_counts = Dataset_final.groupby('DX_bl')['RID'].nunique()\n",
        "\n",
        "print(diagnosis_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwejbsnmxbDf",
        "outputId": "5e514040-094a-4677-f713-9d16216c5415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DX_bl\n",
            "AD      18\n",
            "CN      71\n",
            "EMCI    41\n",
            "LMCI    40\n",
            "SMC     93\n",
            "Name: RID, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "diagnosis_age_stats = Dataset_final.groupby('DX_bl')['AGE'].agg(['mean', 'std'])\n",
        "\n",
        "print(diagnosis_age_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh3IerI8yC-T",
        "outputId": "906a707b-8521-4256-96f5-a53948bd224b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            mean       std\n",
            "DX_bl                     \n",
            "AD     74.048649  9.581772\n",
            "CN     75.576506  7.437953\n",
            "EMCI   72.618478  6.892023\n",
            "LMCI   74.838202  7.954751\n",
            "SMC    73.349020  5.633350\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique_rids_df = Dataset_final.drop_duplicates(subset='RID')\n",
        "\n",
        "# Group by 'DX_bl' and 'PTGENDER' and count unique 'RID' values for each diagnosis and gender\n",
        "diagnosis_gender_counts = unique_rids_df.groupby(['DX_bl', 'PTGENDER']).size().unstack(fill_value=0)\n",
        "\n",
        "print(diagnosis_gender_counts)\n",
        "\n",
        "\n",
        "diagnosis_apor4_counts = unique_rids_df.groupby(['DX_bl', 'APOE4']).size().unstack(fill_value=0)\n",
        "\n",
        "print(diagnosis_apor4_counts)\n",
        "\n",
        "overall_apor4_counts = unique_rids_df['APOE4'].value_counts()\n",
        "\n",
        "print(overall_apor4_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lIDWxbayyYC",
        "outputId": "dea3497a-c8e8-4275-a251-1e14ae67307f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PTGENDER   0   1\n",
            "DX_bl           \n",
            "AD         6  12\n",
            "CN        38  33\n",
            "EMCI      16  25\n",
            "LMCI      18  22\n",
            "SMC       64  29\n",
            "APOE4  0.0  1.0  2.0\n",
            "DX_bl               \n",
            "AD       7    5    6\n",
            "CN      50   21    0\n",
            "EMCI    20   17    4\n",
            "LMCI    21   15    4\n",
            "SMC     53   36    4\n",
            "APOE4\n",
            "0.0    151\n",
            "1.0     94\n",
            "2.0     18\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import f_oneway\n",
        "unique_rids_df = Dataset_final.drop_duplicates(subset='RID')\n",
        "\n",
        "# Group by diagnosis and extract ages for each diagnosis\n",
        "diagnosis_groups = [group['AGE'] for _, group in unique_rids_df.groupby('DX_bl')]\n",
        "\n",
        "# Perform ANOVA test\n",
        "f_stat, p_value = f_oneway(*diagnosis_groups)\n",
        "\n",
        "# Print the result\n",
        "print(\"F-statistic:\", f_stat)\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqUGPVxUpJWh",
        "outputId": "75e293c0-7edf-465d-d8e3-804f8d476754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 2.004055956798235\n",
            "p-value: 0.09437690162619848\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "contingency_table = pd.crosstab(index=unique_rids_df['DX_bl'], columns='count')\n",
        "\n",
        "# Perform chi-square test\n",
        "chi2_stat, p_value, x, y = chi2_contingency(contingency_table)\n",
        "print(contingency_table)\n",
        "\n",
        "print(\"Chi-square statistic:\", chi2_stat)\n",
        "print(\"p-value:\", p_value)\n",
        "print(\"Degrees of freedom:\", x)\n",
        "print(\"Expected frequencies:\\n\", y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2e50y98pvrt",
        "outputId": "6b1ae1b0-2789-4dd2-ed16-80d12fd47812"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "col_0  count\n",
            "DX_bl       \n",
            "AD        18\n",
            "CN        71\n",
            "EMCI      41\n",
            "LMCI      40\n",
            "SMC       93\n",
            "Chi-square statistic: 0.0\n",
            "p-value: 1.0\n",
            "Degrees of freedom: 0\n",
            "Expected frequencies:\n",
            " [[18.]\n",
            " [71.]\n",
            " [41.]\n",
            " [40.]\n",
            " [93.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n",
        "unique_rids_df = Dataset_final.drop_duplicates(subset='RID', keep='first')\n",
        "contingency_table = pd.crosstab(index=unique_rids_df['DX_bl'], columns=unique_rids_df['PTGENDER'])\n",
        "\n",
        "\n",
        "# Perform the Chi-squared test for independence\n",
        "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Chi-squared test statistic:\", chi2)\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsrMMkh_qRyD",
        "outputId": "70a1ef2a-d920-47c1-afe9-ec15ee4a4e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared test statistic: 16.327055580264314\n",
            "p-value: 0.002610283205544789\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contingency_table = pd.crosstab(unique_rids_df['DX_bl'], unique_rids_df['APOE4'])\n",
        "\n",
        "# Perform the chi-square test\n",
        "chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "print(\"Chi-square statistic:\", chi2)\n",
        "print(\"Degrees of freedom:\", dof)\n",
        "print(\"Expected counts:\\n\", expected)\n",
        "print(\"p-value:\", p_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbarCoBos3CH",
        "outputId": "1be46a22-c7bd-4a10-8137-f5caa2668e40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-square statistic: 30.867866917445934\n",
            "Degrees of freedom: 8\n",
            "Expected counts:\n",
            " [[10.33460076  6.43346008  1.23193916]\n",
            " [40.76425856 25.37642586  4.85931559]\n",
            " [23.53992395 14.6539924   2.80608365]\n",
            " [22.96577947 14.29657795  2.73764259]\n",
            " [53.39543726 33.23954373  6.36501901]]\n",
            "p-value: 0.00014831745530370896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kCGNP45rtLj",
        "outputId": "c1776d06-84ce-4824-dda1-6b98d00f1d55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.25.2)\n"
          ]
        }
      ],
      "source": [
        "pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVbz1F_a3j26",
        "outputId": "84d4c4f8-6f11-45e1-d9ac-4e5da6e59f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANOVA test result for AGE: F-statistic = 3.6825903180891286, p-value = 0.005675869790157437\n",
            "Chi-square test result Sex: chi2 = 32.64968217528329, p-value = 1.40890223289544e-06\n",
            "Chi-square test result APOE4: chi2 = 67.8089281836151, p-value = 1.339857077546646e-11\n",
            "Total number of Scans: 588\n",
            "Number of 0s in the females column: 318\n",
            "Number of 1s in the males column: 270\n",
            "Number of 0: 341\n",
            "Number of 1: 210\n",
            "Number of 2: 37\n",
            "Counts of each diagnosis in dataset:\n",
            "DX_bl\n",
            "SMC     204\n",
            "CN      166\n",
            "EMCI     92\n",
            "LMCI     89\n",
            "AD       37\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "import scipy.stats as stats\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "anova_result = stats.f_oneway(*[Dataset_final[Dataset_final['DX_bl'] == category]['AGE'] for category in Dataset_final['DX_bl'].unique()])\n",
        "print(f\"ANOVA test result for AGE: F-statistic = {anova_result.statistic}, p-value = {anova_result.pvalue}\")\n",
        "\n",
        "contingency_table = pd.crosstab(Dataset_final['DX_bl'], Dataset_final['PTGENDER'])\n",
        "# Perform the chi-square test\n",
        "chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "print(f\"Chi-square test result Sex: chi2 = {chi2}, p-value = {p}\")\n",
        "contingency_table = pd.crosstab(Dataset_final['DX_bl'], Dataset_final['APOE4'])\n",
        "chi2, p, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "print(f\"Chi-square test result APOE4: chi2 = {chi2}, p-value = {p}\")\n",
        "\n",
        "all_count = Dataset_final['RID'].count()\n",
        "print(f\"Total number of Scans: {all_count}\")\n",
        "\n",
        "value_counts = Dataset_final['PTGENDER'].value_counts()\n",
        "count_0 = value_counts.get(0, 0)  # Gets the count for 0, or returns 0 if not present\n",
        "count_1 = value_counts.get(1, 0)\n",
        "print(f\"Number of 0s in the females column: {count_0}\")\n",
        "print(f\"Number of 1s in the males column: {count_1}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "apoe4_count = Dataset_final['APOE4'].value_counts()\n",
        "count_0 = apoe4_count.get(0, 0)  # Gets the count for 0, or returns 0 if not present\n",
        "count_1 = apoe4_count.get(1, 0)\n",
        "count_2 = apoe4_count.get(2, 0)\n",
        "print(f\"Number of 0: {count_0}\")\n",
        "print(f\"Number of 1: {count_1}\")\n",
        "print(f\"Number of 2: {count_2}\")\n",
        "\n",
        "dx_bl_counts = Dataset_final['DX_bl'].value_counts()\n",
        "\n",
        "print(\"Counts of each diagnosis in dataset:\")\n",
        "print(dx_bl_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "id": "HACi2H2yZqnn",
        "outputId": "0748e1a0-2b41-4ddf-81ac-9dace05055bb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Calculate few statistics for the dataset\n",
        "\n",
        "\n",
        "def plot_age_stats_per_diagnosis(df):\n",
        "    \"\"\"\n",
        "    Computes the mean and standard deviation of the 'AGE' column per 'DX_bl' diagnosis category in the dataset,\n",
        "    grouped by unique 'RID'. It then plots a table showing these statistics with a white background and increases\n",
        "    row size for better readability. Age statistics are displayed with precision up to the fourth decimal point.\n",
        "\n",
        "    Parameters:\n",
        "    - df: A pandas DataFrame with columns 'RID', 'AGE', and 'DX_bl'.\n",
        "\n",
        "    Returns:\n",
        "    - A matplotlib plot (table) showing the mean and standard deviation of age per diagnosis category.\n",
        "    \"\"\"\n",
        "    import pandas as pd\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    # Grouping the data by 'RID' to find mean and std of AGE for each patient\n",
        "    age_stats_per_patient = df.groupby('RID')['AGE'].agg(['mean', 'std']).reset_index()\n",
        "    age_stats_per_patient['std'] = age_stats_per_patient['std'].fillna(0)  # Fill NaN std with 0\n",
        "\n",
        "    # Merging stats back with diagnosis information, after removing duplicate RIDs\n",
        "    df_no_duplicates = df.drop_duplicates(subset='RID')\n",
        "    final_dataset = pd.merge(df_no_duplicates[['RID', 'DX_bl']], age_stats_per_patient, on='RID')\n",
        "\n",
        "    # Grouping by 'DX_bl' for overall mean and std of AGE mean per diagnosis\n",
        "    age_stats_per_diagnosis = final_dataset.groupby('DX_bl')['mean'].agg(['mean', 'std']).reset_index()\n",
        "\n",
        "    # Adjusting precision to the 2nd decimal point\n",
        "    age_stats_per_diagnosis['mean'] = age_stats_per_diagnosis['mean'].round(2)\n",
        "    age_stats_per_diagnosis['std'] = age_stats_per_diagnosis['std'].round(2)\n",
        "\n",
        "    # Plotting\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_axis_off()\n",
        "    table_data = age_stats_per_diagnosis.values.tolist()\n",
        "    columns = [\"Diagnosis\", \"Mean Age\", \"Age STD\"]\n",
        "    table = ax.table(cellText=table_data, colLabels=columns, loc='center', cellLoc='center', rowLoc='center')\n",
        "    table.set_fontsize(11)\n",
        "    table.scale(0.9, 2)  # Adjusting scale for better readability\n",
        "\n",
        "\n",
        "    for pos, cell in table.get_celld().items():\n",
        "        cell.set_height(.1)  # Adjusting the row height\n",
        "\n",
        "    ax.set_title('Mean and STD of Age per Diagnosis', fontweight='bold')\n",
        "    plt.gcf().set_size_inches(8, 3)\n",
        "    plt.gca().patch.set_facecolor('white')\n",
        "    plt.gca().axis('off')\n",
        "    plt.show()\n",
        "\n",
        "plot_age_stats_per_diagnosis(Dataset_final)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "awJnmoUj0A_G",
        "outputId": "a82f7242-43cb-4974-c019-93de5b4cf322"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# We can use a boxplot to visualize the age distribution within each diagnosis, separated by gender\n",
        "df = Dataset_final\n",
        "# Create a new 'Gender' column with string values for better visualization\n",
        "df['Gender'] = df['PTGENDER'].map({1: 'Male', 0: 'Female'})\n",
        "# Rename 'CN' in 'DX_bl' column to 'CU'\n",
        "df['DX_bl'] = df['DX_bl'].replace({'CN': 'CU'})\n",
        "\n",
        "\n",
        "# Ensure 'DX_bl' is of type category with the given order\n",
        "order = ['CU', 'SMC', 'EMCI', 'LMCI', 'AD']\n",
        "df['DX_bl'] = pd.Categorical(df['DX_bl'], categories=order, ordered=True)\n",
        "\n",
        "# Now, when you plot, the categories will appear in the defined order\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.boxplot(data=df, x='DX_bl', y='AGE', hue='Gender', order=order)\n",
        "plt.title('Age Distribution per Diagnosis, Separated by Sex')\n",
        "plt.xlabel('Diagnosis')\n",
        "plt.ylabel('Age')\n",
        "plt.legend(title='Sex')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHBPaAy5RAPf"
      },
      "source": [
        "# Splits fnc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-8_3QvaGKfB",
        "outputId": "929f63c0-f566-432d-b406-3e5ba05f0ce7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(588, 92)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "\n",
        "#age_mean = Dataset_final['AGE'].mean()\n",
        "#age_std = Dataset_final['AGE'].std()\n",
        "#Dataset_final.loc[:, 'AGE'] = (Dataset_final['AGE'] - age_mean) / age_std\n",
        "#print mean and std\n",
        "#print('AGE Mean',age_mean)\n",
        "#print('AGE std',age_std)\n",
        "\n",
        "\n",
        "#APPLY Z-SCORE TO NORMALIZE AGE, PRINT MEAN & STD for future records\n",
        "#Dataset_final.loc[:, 'AGE'] = (Dataset_final['AGE'] - age_mean) / age_std\n",
        "\n",
        "#move time difference to last column\n",
        "cols =  [col for col in Dataset_final.columns if col != 'Time_Difference']+['Time_Difference']\n",
        "Dataset_final = Dataset_final[cols]\n",
        "\n",
        "\n",
        "timepoints_count = Dataset_final.groupby('RID').size().reset_index(name='num_timepoints')\n",
        "modified_set = Dataset_final.merge(timepoints_count, on='RID', how='left')\n",
        "modified_set.rename(columns={'num_timepoints_x': 'num_timepoints'}, inplace=True)\n",
        "# This should be applied to 'modified_set', not 'Dataset_final', since 'modified_set' is the updated DataFrame\n",
        "cols = ['num_timepoints'] + [col for col in modified_set.columns if col != 'num_timepoints']\n",
        "modified_set = modified_set[cols]\n",
        "\n",
        "modified_set.head()\n",
        "Dataset_final=modified_set\n",
        "Dataset_final.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fekmEfFX77pP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# List of diagnosis columns\n",
        "diagnostic_cols = ['DX_bl_AD', 'DX_bl_CN', 'DX_bl_EMCI', 'DX_bl_LMCI', 'DX_bl_SMC']\n",
        "\n",
        "# Grouping dataset by 'RID' to work on each patient's data\n",
        "\n",
        "\n",
        "# Splitting patient IDs into training and testing groups, ensuring each group has a proportional representation of diagnoses\n",
        "# 'test_size=0.2' means 20% of the data goes into the test set\n",
        "# 'random_state=11' ensures the split is reproducible\n",
        "# 'stratify=RID_diagnosis['DX_bl']' ensures the split is stratified by the diagnosis\n",
        "\n",
        "\n",
        "def generate_n_splits(Dataset_final, n_splits, test_size=0.2, random_state=11):\n",
        "\n",
        "\n",
        "    grouped = Dataset_final.groupby('RID')\n",
        "    RID_diagnosis = grouped['DX_bl'].agg(lambda x: x.mode()[0]).reset_index()\n",
        "    #print(RID_diagnosis.head())\n",
        "    #print(RID_diagnosis.shape)\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    splits = {}\n",
        "\n",
        "    # Generate indices for each split\n",
        "    for idx, (train_index, test_index) in enumerate(skf.split(RID_diagnosis, RID_diagnosis['DX_bl'])):\n",
        "        train_RIDs = RID_diagnosis.iloc[train_index]\n",
        "        test_RIDs = RID_diagnosis.iloc[test_index]\n",
        "\n",
        "        # Filter the main dataset to create train and test sets based on the indices\n",
        "        train = Dataset_final[Dataset_final['RID'].isin(train_RIDs['RID'])]\n",
        "        test = Dataset_final[Dataset_final['RID'].isin(test_RIDs['RID'])]\n",
        "\n",
        "        # Store each train and test pair in the dictionary with dynamic naming\n",
        "        splits[f'train{idx+1}'] = train\n",
        "        splits[f'test{idx+1}'] = test\n",
        "\n",
        "    # Optionally print out unique RID counts for each split\n",
        "    for i in range(1, n_splits+1):\n",
        "        print(f\"Split {i}: Number of unique RID train: {splits[f'train{i}']['RID'].nunique()}, Number of unique RID test: {splits[f'test{i}']['RID'].nunique()}\")\n",
        "        print(\"This is generate_n_splits_and_store function \\n\")\n",
        "    return splits\n",
        "\n",
        "Outer_Loop_Splits=5\n",
        "\n",
        "dataset_splits = generate_n_splits(Dataset_final, Outer_Loop_Splits)\n",
        "\n",
        "# Accessing variables\n",
        "train1 = dataset_splits['train1']\n",
        "test1 = dataset_splits['test1']\n",
        "train2 = dataset_splits['train2']\n",
        "test2 = dataset_splits['test2']\n",
        "train3 = dataset_splits['train3']\n",
        "test3 = dataset_splits['test3']\n",
        "train4 = dataset_splits['train4']\n",
        "test4 = dataset_splits['test4']\n",
        "train5 = dataset_splits['train5']\n",
        "test5 = dataset_splits['test5']\n",
        "\n",
        "Dataset_final.shape\n",
        "print(type(Dataset_final))\n",
        "print(type(train1))\n",
        "\n",
        "print(train1.shape)\n",
        "print(test1.shape)\n",
        "print('\\n')\n",
        "Dataset_final.shape\n",
        "train1.head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95H0zwIYOaXs",
        "outputId": "884bc77c-b8d4-4b49-9acd-c5438a4e402c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique RID Total : 263\n",
            "Number of data points Total: 588\n",
            "Number of unique RID in Training: 210\n",
            "Number of data points in the training dataset: 468\n",
            "Number of unique RID in Testing: 53\n",
            "Number of data points in the testing dataset: 120\n",
            "Number of unique RID in Training: 210\n",
            "Number of data points in the training dataset: 465\n",
            "Number of unique RID in Testing: 53\n",
            "Number of data points in the testing dataset: 123\n",
            "Number of unique RID in Training: 210\n",
            "Number of data points in the training dataset: 471\n",
            "Number of unique RID in Testing: 53\n",
            "Number of data points in the testing dataset: 117\n",
            "Number of unique RID in Training: 211\n",
            "Number of data points in the training dataset: 473\n",
            "Number of unique RID in Testing: 52\n",
            "Number of data points in the testing dataset: 115\n",
            "Number of unique RID in Training: 211\n",
            "Number of data points in the training dataset: 475\n",
            "Number of unique RID in Testing: 52\n",
            "Number of data points in the testing dataset: 113\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def plot_histograms(train_dataset, test_dataset, feature_mapping, set1, set2):\n",
        "    # Custom feature names in the desired order\n",
        "    custom_feature_names = ['CU', 'SMC', 'EMCI', 'LMCI', 'AD']\n",
        "    bar_width = 0.2\n",
        "    index = np.arange(len(custom_feature_names))\n",
        "\n",
        "    train_counts = []\n",
        "    test_counts = []\n",
        "\n",
        "    for custom_name in custom_feature_names:\n",
        "        # Use the mapping to get the actual dataset column name\n",
        "        col = feature_mapping[custom_name]\n",
        "\n",
        "        train_count = train_dataset[col].value_counts().get(1, 0)\n",
        "        test_count = test_dataset[col].value_counts().get(1, 0)\n",
        "        train_counts.append(train_count)\n",
        "        test_counts.append(test_count)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(index, train_counts, bar_width, label=set1)\n",
        "    plt.bar(index + bar_width, test_counts, bar_width, label=set2)\n",
        "\n",
        "    plt.xlabel('Diagnosis')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title('Diagnosis in Training and Testing')\n",
        "    plt.xticks(index + bar_width / 2, custom_feature_names)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "feature_mapping = {\n",
        "    'CU': 'DX_bl_CN',\n",
        "    'SMC': 'DX_bl_SMC',\n",
        "    'EMCI': 'DX_bl_EMCI',\n",
        "    'LMCI': 'DX_bl_LMCI',\n",
        "    'AD': 'DX_bl_AD'\n",
        "}\n",
        "\n",
        "unique_rid_count = Dataset_final['RID'].nunique()\n",
        "print(f\"Number of unique RID Total : {unique_rid_count}\")\n",
        "num_datapoints = Dataset_final.shape[0]\n",
        "print(f\"Number of data points Total: {num_datapoints}\")\n",
        "\n",
        "def summarize_dataset(train, test):\n",
        "    \"\"\"\n",
        "    Print summary statistics for training and testing datasets including the number of unique RIDs\n",
        "    and the total number of data points.\n",
        "\n",
        "    Args:\n",
        "    train (DataFrame): The training dataset.\n",
        "    test (DataFrame): The testing dataset.\n",
        "    \"\"\"\n",
        "    # Training set summary\n",
        "    unique_rid_count_train = train['RID'].nunique()\n",
        "    num_datapoints_train = train.shape[0]\n",
        "    print(f\"Number of unique RID in Training: {unique_rid_count_train}\")\n",
        "    print(f\"Number of data points in the training dataset: {num_datapoints_train}\")\n",
        "\n",
        "    # Testing set summary\n",
        "    unique_rid_count_test = test['RID'].nunique()\n",
        "    num_datapoints_test = test.shape[0]\n",
        "    print(f\"Number of unique RID in Testing: {unique_rid_count_test}\")\n",
        "    print(f\"Number of data points in the testing dataset: {num_datapoints_test}\")\n",
        "\n",
        "\n",
        "summarize_dataset(train1, test1)\n",
        "summarize_dataset(train2, test2)\n",
        "summarize_dataset(train3, test3)\n",
        "summarize_dataset(train4, test4)\n",
        "summarize_dataset(train5, test5)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "05-GeTDT95MN"
      },
      "outputs": [],
      "source": [
        "with pd.option_context('display.max_columns', None):  # None means unlimited\n",
        "    display(train1.head(1))\n",
        "# tau  1.303\tto  1.482"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ZelFDHRKsS"
      },
      "source": [
        "# Features Extract- Target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NnfTPmGYD7r"
      },
      "outputs": [],
      "source": [
        "def extract_features_and_targets(data):\n",
        "    \"\"\"\n",
        "    Processes the dataset to extract features and targets for each RID group.\n",
        "    Features include tau and amyloid values, while targets are future tau values.\n",
        "    Exclude the last 6 columns which are RID, PTGEN etc demographics features, except for the diag column which is included in features.\n",
        "\n",
        "    Parameters:\n",
        "    - data: DataFrame containing the entire dataset.\n",
        "\n",
        "    Returns:\n",
        "    - X_all: A list of brain regions with all suvr values\n",
        "    - y_all: A list of target arrays for all applicable data points.\n",
        "    - rids_all: A list of RIDs for all applicable data points, aligned with X_all and y_all.\n",
        "    - diag_array: A list of diagnostic features aligned with X_all.\n",
        "    - target_names: A list of target names aligned with y.\n",
        "    \"\"\"\n",
        "    X_all = []\n",
        "    y_all = []\n",
        "    rids_all = []\n",
        "    diag_array = []\n",
        "    bias = []\n",
        "    Age_all = []\n",
        "    PTGENDER_all = []\n",
        "    y_col_names = []\n",
        "    timediff=[]\n",
        "    Apoe_all=[]\n",
        "    # Loop over each RID\n",
        "    for rid, group in data.groupby('RID'):\n",
        "        # Exclude the last 6 columns which are assumed to be diagnostic features\n",
        "        # And include the diag feature column (index 4) for diagnostic purposes\n",
        "        all_tau_features = group.iloc[:, 6:-6]\n",
        "        diag_feature = group.iloc[:, 3]\n",
        "        datapoints=group.iloc[:, 0]\n",
        "        PTGENDER = group.iloc[:, 2]\n",
        "        AGE = group.iloc[:, 4]\n",
        "        #Assumes that the last column is \"Time_Difference\"\n",
        "        Delta_t=group.iloc[:, -1]\n",
        "        apoe_list=group.iloc[:,5]\n",
        "        #print(Delta_t)\n",
        "\n",
        "        # Extract tau value\n",
        "        # Filter out amyloid columns for X, but keep them for y prediction target\n",
        "        tau_columns = [col for col in all_tau_features.columns if not col.endswith('_AMY')]\n",
        "        amy_columns = [col for col in all_tau_features.columns if col.endswith('_AMY')]\n",
        "\n",
        "        # Extract tau and amyloid values\n",
        "        tau_values = group[tau_columns].values\n",
        "        amy_values = group[amy_columns].values\n",
        "\n",
        "        if not y_col_names:\n",
        "          y_col_names = tau_columns\n",
        "        # Iterate over the group to align current features with future tau values\n",
        "        for i in range(len(tau_values) - 1):  # Ensure there's a next time point to predict\n",
        "            # Current features include both current tau and amyloid values\n",
        "            X = np.concatenate((tau_values[i], amy_values[i]), axis=None)\n",
        "\n",
        "            # Future tau values as target\n",
        "            y = tau_values[i + 1]  # next row represents the future time point\n",
        "\n",
        "            # Append the current features and future tau values to their respective lists\n",
        "            X_all.append(X)\n",
        "            y_all.append(y)\n",
        "            timediff.append(Delta_t.iloc[i+1])\n",
        "            diag_array.append(diag_feature.iloc[i])  # Append the diagnostic feature\n",
        "            bias.append(datapoints.iloc[i])  # Append the datapoint\n",
        "            Age_all.append(AGE.iloc[i])\n",
        "            Apoe_all.append(apoe_list.iloc[i])\n",
        "            PTGENDER_all.append(PTGENDER.iloc[i])\n",
        "            rids_all.append(rid)\n",
        "    adjusted_bias =  [x - 1 for x in bias] # 2 scans mean 1 observation thus -1\n",
        "    return np.array(X_all), np.array(y_all), np.array(rids_all), np.array(diag_array), np.array(adjusted_bias), y_col_names, np.array(timediff), np.array(Age_all), np.array(PTGENDER_all), np.array(Apoe_all)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5jfLSY0kjiK"
      },
      "outputs": [],
      "source": [
        "#train_set=remove_Amy(train1)\n",
        "#test=remove_Amy(test1)\n",
        "\n",
        "\n",
        "# bias test and train refers to the number of data points each RID has, min is 2 max is 4\n",
        "\n",
        "#np.array(X_all), np.array(y_all), np.array(rids_all), np.array(diag_array), np.array(datapoints_array), y_col_names, np.array(timediff), np.array(Age_all), np.array(PTGENDER_all), np.array(Apoe_all)\n",
        "#Prepare labels\n",
        "X_train, y_train,train_rid,diag_array, bias_train, roi , Time_diff_train, age_train, gndr_train, apoe_train=extract_features_and_targets(Dataset_final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpEaRJfQKO8s"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgDJDQWZ046V"
      },
      "outputs": [],
      "source": [
        "age_train_df=pd.DataFrame(apoe_train)\n",
        "age_train_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnKxcIIq1BEw"
      },
      "outputs": [],
      "source": [
        "gndr_train_df=pd.DataFrame(gndr_train)\n",
        "gndr_train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWCVcvdKRaE9"
      },
      "source": [
        "# GGSEG features mapping + Correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQpo79v4k8SM"
      },
      "outputs": [],
      "source": [
        "from math import nan\n",
        "from itertools import islice\n",
        "#roi was extracted prevously as a list roi\n",
        "# Removing \"CTX_\", \"_SUVR\" from each string and converting to lowercase\n",
        "print(roi)\n",
        "processed_list_step1 = [item.replace('CTX_', '').replace('_SUVR', '').lower() for item in roi]\n",
        "processed_list_step2 = [\n",
        "    item.replace('rh_', '') + '_right' if 'rh_' in item else item\n",
        "    for item in processed_list_step1]\n",
        "processed_list_step3 = [\n",
        "    item.replace('lh_', '') + '_left' if 'lh_' in item else item\n",
        "    for item in processed_list_step2]\n",
        "\n",
        "\n",
        "\n",
        "def replace_accumbens_area(data):\n",
        "    replaced_data = []\n",
        "    for item in data:\n",
        "        if item == 'left_accumbens_area':\n",
        "            replaced_data.append('NA_left')\n",
        "        elif item == 'right_accumbens_area':\n",
        "            replaced_data.append('NA_right')\n",
        "        else:\n",
        "            replaced_data.append(item)\n",
        "    return replaced_data\n",
        "\n",
        "\n",
        "\n",
        "processed_list_step4 = replace_accumbens_area(processed_list_step3)\n",
        "print(processed_list_step4)\n",
        "print (len(processed_list_step4))\n",
        "\n",
        "# The following code is how we found missing regions list\n",
        "#unique_to_processed_list= [item for item in processed_list_step4 if item not in roi_list and item not in brain_regions ]\n",
        "#print(\"missing regions\", unique_to_processed_list)\n",
        "#print(len(unique_to_processed_list))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"Put the remanining regions in our dataset in a list \\n\")\n",
        "# Put the remanining regions in our dataset in a list\n",
        "\n",
        "missing_regions = ['left_amygdala', 'left_caudate', 'left_hippocampus', 'left_pallidum', 'left_putamen', 'left_thalamus_proper', 'right_amygdala', 'right_caudate', 'right_hippocampus', 'right_pallidum', 'right_putamen', 'right_thalamus_proper']\n",
        "\n",
        "\n",
        "def transform_string(s):\n",
        "    return '-'.join(part.capitalize() for part in s.split('_'))\n",
        "\n",
        "# Transform strings in unique_to_processed_list based on their presence and format in missing_regions\n",
        "transformed_unique_to_processed_list = []\n",
        "for s in processed_list_step4:\n",
        "    if 'proper' in s.lower():\n",
        "            s = s.replace('_proper', '')\n",
        "            transformed_s = transform_string(s)\n",
        "            transformed_unique_to_processed_list.append(transformed_s)\n",
        "    elif s.lower() in [s.lower() for s in missing_regions]:\n",
        "        # Apply transformation if the lowercase version matches\n",
        "        transformed_s = transform_string(s)\n",
        "        transformed_unique_to_processed_list.append(transformed_s)\n",
        "    else:\n",
        "      transformed_unique_to_processed_list.append(s)\n",
        "\n",
        "\n",
        "\n",
        "Features= transformed_unique_to_processed_list\n",
        "print(Features)\n",
        "print(len(Features))\n",
        "\n",
        "#Final_Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REqVrvKZyTx_"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALppPQx1a7p7"
      },
      "outputs": [],
      "source": [
        "Dataset_final.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu4cZzEx9z4a",
        "outputId": "0e6d7eed-ab51-4c12-92b0-84a7a5ef4e16"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pandas._libs.tslibs.timedeltas.Timedelta"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(Dataset_final['Time_Difference'][1] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xKaNnB41hAG"
      },
      "outputs": [],
      "source": [
        "def plot_correlation_matrix_with_labels_and_numbers(X, feature_names):\n",
        "    # Ensure feature_names has the same length as the number of features in X\n",
        "    assert X.shape[1] == len(feature_names), \"The length of feature_names must match the number of features in X\"\n",
        "\n",
        "    # Calculate the correlation matrix\n",
        "    corr_matrix = np.corrcoef(X, rowvar=False)\n",
        "    vmax = np.abs(corr_matrix).max()\n",
        "    # Plotting the correlation matrix\n",
        "    fig, ax = plt.subplots(figsize=(12, 10))\n",
        "    cax = ax.matshow(corr_matrix, cmap='coolwarm', vmin=0, vmax=vmax)\n",
        "    plt.title('Correlation Matrix', pad=20)\n",
        "\n",
        "    # Adding a color bar to make interpretation easier\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Setting the ticks and labels with the feature names\n",
        "    ticks = np.arange(len(feature_names))\n",
        "    plt.xticks(ticks, feature_names, rotation=90)\n",
        "    plt.yticks(ticks, feature_names)\n",
        "\n",
        "    # Annotating each cell with the correlation coefficient\n",
        "    for i in range(len(feature_names)):\n",
        "        for j in range(len(feature_names)):\n",
        "            text = ax.text(j, i, f\"{corr_matrix[i, j]:.2f}\",\n",
        "                           ha=\"center\", va=\"center\", color=\"w\")\n",
        "\n",
        "    ax.set_xlabel('Feature')\n",
        "    ax.set_ylabel('Feature')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# use only cross sectional data for correlation\n",
        "\n",
        "unique_RID_df = Dataset_final.drop_duplicates(subset='RID')\n",
        "\n",
        "# Columns to drop\n",
        "columns_to_drop = [\n",
        "    'RID', 'PTGENDER', 'DX_bl', 'AGE', 'APOE4', 'DX_bl_AD', 'DX_bl_CN',\n",
        "    'DX_bl_EMCI', 'DX_bl_LMCI', 'DX_bl_SMC', 'Gender', 'Time_Difference'\n",
        "]\n",
        "\n",
        "# Dropping the specified columns from Dataset_final and saving the result in d\n",
        "D = unique_RID_df.drop(columns=columns_to_drop)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Keep_columns = [col for col in D.columns if not col.endswith('_AMY')]\n",
        "D_filtered = D[Keep_columns]\n",
        "\n",
        "#print(D_filtered.shape)\n",
        "#print(D_filtered.head())\n",
        "\n",
        "\n",
        "words = ['amygdala', 'accumbens', 'caudate', 'hippocampus', 'pallidum', 'putamen', 'thalamus']\n",
        "D_columns = D_filtered.columns\n",
        "Keep_columns = [col for col in D_columns if any(word in col.lower() for word in words) and col in D_columns]\n",
        "Subcortical_df=D_filtered[Keep_columns]\n",
        "Subcortical_feature_list= [feature for feature in Features if any(word in feature.lower() for word in words)]\n",
        "\n",
        "print(Subcortical_feature_list)\n",
        "print(Subcortical_df.shape)\n",
        "print(len(Subcortical_feature_list))\n",
        "\n",
        "#plot_correlation_matrix_with_labels_and_numbers(Subcortical_df,Subcortical_feature_list)\n",
        "\n",
        "\n",
        "def plot_correlation_matrix_with_labels_no_numbers(X, feature_names):\n",
        "    # Ensure feature_names has the same length as the number of features in X\n",
        "    assert X.shape[1] == len(feature_names), \"The length of feature_names must match the number of features in X\"\n",
        "\n",
        "    # Calculate the correlation matrix\n",
        "    corr_matrix = np.corrcoef(X, rowvar=False)\n",
        "    vmax = np.abs(corr_matrix).max()\n",
        "\n",
        "    # Plotting the correlation matrix\n",
        "    fig, ax = plt.subplots(figsize=(19, 19))\n",
        "    cax = ax.matshow(corr_matrix, cmap='coolwarm', vmin=0, vmax=vmax)\n",
        "\n",
        "    plt.title('Correlation Matrix', pad=20)\n",
        "\n",
        "    # Adding a color bar to make interpretation easier\n",
        "    fig.colorbar(cax)\n",
        "\n",
        "    # Setting the ticks and labels with the feature names\n",
        "    ticks = np.arange(len(feature_names))\n",
        "    plt.xticks(ticks, feature_names, rotation=90)\n",
        "    plt.yticks(ticks, feature_names)\n",
        "\n",
        "    ax.set_xlabel('Feature')\n",
        "    ax.set_ylabel('Feature')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#plot_correlation_matrix_with_labels_no_numbers(D_filtered, Features)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhHOLs4aRqFL"
      },
      "source": [
        "# Grid Seach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2eahHH40CMdN",
        "outputId": "b10666df-570d-46e1-ade5-62d36bc9b75e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Outer_Loop\n",
            "(475, 92)\n",
            "Outer_Loop \n",
            "\n",
            "Split 1: Number of unique RID train: 168, Number of unique RID test: 43\n",
            "This is generate_n_splits_and_store function \n",
            "\n",
            "Split 2: Number of unique RID train: 169, Number of unique RID test: 42\n",
            "This is generate_n_splits_and_store function \n",
            "\n",
            "Split 3: Number of unique RID train: 169, Number of unique RID test: 42\n",
            "This is generate_n_splits_and_store function \n",
            "\n",
            "Split 4: Number of unique RID train: 169, Number of unique RID test: 42\n",
            "This is generate_n_splits_and_store function \n",
            "\n",
            "Split 5: Number of unique RID train: 169, Number of unique RID test: 42\n",
            "This is generate_n_splits_and_store function \n",
            "\n",
            "Number of unique RID in Training: 168\n",
            "Number of data points in the training dataset: 376\n",
            "Number of unique RID in Testing: 43\n",
            "Number of data points in the testing dataset: 99\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.14799729827163474\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.14046866487679738\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.17333230333977512\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.17619425768011382\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1356032339156738\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.14475056484799298\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1391588656228568\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1529370304835694\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13486435064045446\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1288348342281367\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13677529715725353\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.14118619869181087\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12760612357365234\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12517366444681371\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "0.12038729907135877\n",
            "Fold: 1, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.11615350853108934\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13401345061223421\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.13195259776402796\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.13417004892836726\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.16892152651096032\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1355319777536605\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13179275405843344\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1396975337621357\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "0.1408912868546588\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12726487083254115\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12623290693706699\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1284717714886048\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12335573056404078\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12978391082744514\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13387490387388637\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.11803579629904459\n",
            "Fold: 1, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "0.13177139263892812\n",
            "Number of unique RID in Training: 169\n",
            "Number of data points in the training dataset: 379\n",
            "Number of unique RID in Testing: 42\n",
            "Number of data points in the testing dataset: 96\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12055365205539596\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13604726102915077\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.16658448550513497\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.14565854321740296\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.11819368697504204\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1413674836659873\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13168318745990595\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1549240577982532\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.11663651041962482\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12941959660737604\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1329005692554845\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.11924580737065385\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1140148596766922\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.10692043621804981\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12642171778877576\n",
            "Fold: 2, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.10895529673463769\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12413794623083538\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1168994891524315\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.13392369829802603\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.13788902202502445\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12885465433961815\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12319383058934301\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1252128114199197\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12147354197016469\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.11228454864676354\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.10746966710068562\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.10621024778728132\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.11423261282223243\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.11067317866241491\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.10823189535306561\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.11149309841449613\n",
            "Fold: 2, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12056135192138177\n",
            "Number of unique RID in Training: 169\n",
            "Number of data points in the training dataset: 381\n",
            "Number of unique RID in Testing: 42\n",
            "Number of data points in the testing dataset: 94\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1870714128661614\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.18759594140041333\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.2415085058238644\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1973976260409905\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "0.19277135276828822\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1786975503835541\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1820092905290998\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "0.19059397962895724\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1671350170619213\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.16734716984365994\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "0.17853567447387256\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.18440102427925628\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.16293947724934954\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.15784678687281334\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.15369427924520124\n",
            "Fold: 3, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "0.1516135483278105\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.20458042741016697\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.2046578675732446\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.17193130002606374\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.17869847560327212\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.17557178751253164\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.19080442670904674\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.18111199151862126\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.17781861335087853\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.16942645950145446\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.17127834878403408\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.16922425632007565\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.16689069460388276\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1697911784696321\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1676254842828386\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.154596312770294\n",
            "Fold: 3, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.16419232003015397\n",
            "Number of unique RID in Training: 169\n",
            "Number of data points in the training dataset: 382\n",
            "Number of unique RID in Testing: 42\n",
            "Number of data points in the testing dataset: 93\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.14298228226175494\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1494204713987369\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "0.15683847940762838\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.16611292613323997\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.13914941576240109\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.13856487736479908\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.14258877249523705\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13653209919625636\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12380617670720699\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12877240789146988\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1370241899109354\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1368958327795945\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1259792068503651\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12822639034483946\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12379928350261613\n",
            "Fold: 4, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12942698471277367\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.140184881465809\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.14888157185362835\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13476153310560712\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.17212059473430408\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 7ms/step\n",
            "0.1332244581680672\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1292246757378765\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "0.13307285380234907\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.13039121261864314\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.13902894088929774\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12318297301297094\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.127608993685041\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.14106698938351053\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12427546285601224\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13394693190245066\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12297022921068997\n",
            "Fold: 4, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12554665440040477\n",
            "Number of unique RID in Training: 169\n",
            "Number of data points in the training dataset: 382\n",
            "Number of unique RID in Testing: 42\n",
            "Number of data points in the testing dataset: 93\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.15196074900755696\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1454603118445359\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1592843271280036\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.15846420436174263\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.14010627244909601\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.15075773416500465\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.16043798110707136\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.17389760590230718\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1420897136105042\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1317895579042388\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1166603907834081\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 6ms/step\n",
            "0.17532446489334105\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12126323904348354\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.11456572891450396\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12020191695386288\n",
            "Fold: 5, Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12091488436589053\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12767241254939754\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1334939485059065\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.14256087744235993\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1407274163361858\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.14324513663369068\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12675091734844096\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1366296738096312\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 200, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.12791203917568805\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.11999139745165321\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.13498541703376116\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12210350469222256\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 3, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12908334696047447\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 16\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1263423426178156\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 32\n",
            "2/2 [==============================] - 0s 5ms/step\n",
            "0.1264674981575386\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 64\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.12138285134610008\n",
            "Fold: 5, Hyperparameters: Activation: elu, LR: 0.001, Epochs: 600, Hidden Layers: 4, Neurons/Layer: 128\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "0.1185074733882558\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "def GridSearch(train_data, activations, learning_rates, epochs_list, hidden_layers_list, neurons_per_layer_list, n_splits):\n",
        "    best_overall_mae = float('inf')\n",
        "    best_hyperparameters_per_fold = []\n",
        "    #print(train_data.shape)\n",
        "    #train_set=remove_Amy(train_data)\n",
        "    dataset_splits = generate_n_splits(train_data, n_splits)\n",
        "\n",
        "    # Iterate over each fold\n",
        "    for i in range(1,n_splits+1):\n",
        "        best_mae_for_fold = float('inf')\n",
        "        best_hyperparameters_for_fold = {}\n",
        "        key1 = f'test{i}'\n",
        "        Validation_set= dataset_splits[key1]\n",
        "        key2 = f'train{i}'\n",
        "        Training_set= dataset_splits[key2]\n",
        "        summarize_dataset(Training_set,Validation_set)\n",
        "        # Standardize the age column using Z-score\n",
        "        merged_set = pd.concat([Validation_set, Training_set], ignore_index=True)\n",
        "        age_mean = merged_set['AGE'].mean()\n",
        "        age_std = merged_set['AGE'].std()\n",
        "        Validation_set.loc[:, 'AGE'] = (Validation_set['AGE'] - age_mean) / age_std\n",
        "        Training_set.loc[:, 'AGE'] = (Training_set['AGE'] - age_mean) / age_std\n",
        "\n",
        "        # 160 feature\n",
        "        X_train, y_train,train_rid,diag_array_train, bias_train, roi , Time_diff_train, age_train, gndr_train, apoe_train=extract_features_and_targets(Training_set)\n",
        "        X_validation, y_validation,test_rid,diag_array_test, bias_validation, roi , Time_diff_test, age_test, gndr_test, apoe_test=extract_features_and_targets(Validation_set)\n",
        "        # print(\"First value of train_rid:\", train_rid[0])\n",
        "        # print(\"First value of diag_array_train:\", diag_array_train[0])\n",
        "        # print(\"First value of bias_train:\", bias_train[0])\n",
        "        # print(\"First value of roi:\", roi[0])\n",
        "        # print(\"First value of Time_diff_train:\", Time_diff_train[0])\n",
        "        # print(\"First value of age_train:\", age_train[0])\n",
        "        # print(\"First value of gndr_train:\", gndr_train[0])\n",
        "        # print(\"First value of apoe_train:\", apoe_train[0])\n",
        "        X_train = preprocess_data(X_train, diag_array_train, age_train, gndr_train, apoe_train, Time_diff_train)\n",
        "        X_validation = preprocess_data(X_validation, diag_array_test, age_test, gndr_test, apoe_test, Time_diff_test)\n",
        "\n",
        "\n",
        "        # Iterate over each combination of hyperparameters for the current fold\n",
        "        for activation in activations:\n",
        "            for learning_rate in learning_rates:\n",
        "                for epochs in epochs_list:\n",
        "                    for hidden_layers in hidden_layers_list:\n",
        "                        for neurons_per_layer in neurons_per_layer_list:\n",
        "                            print(f\"Fold: {i}, Hyperparameters: Activation: {activation}, LR: {learning_rate}, Epochs: {epochs}, Hidden Layers: {hidden_layers}, Neurons/Layer: {neurons_per_layer}\")\n",
        "\n",
        "                            # Train and evaluate the model on the current fold and hyperparameter combination\n",
        "                            model = train_mlp_model(X_train, y_train, X_validation, y_validation, activation, bias_train, bias_validation, learning_rate, epochs, hidden_layers, neurons_per_layer)\n",
        "                            mae_dic_new, mae_avg = evaluate_model_per_feature(model, X_validation, y_validation)\n",
        "                            print(mae_avg)\n",
        "                            if mae_avg < best_mae_for_fold:\n",
        "                              best_mae_for_fold = mae_avg\n",
        "                              best_hyperparameters_for_fold = {'fold' : i,'activation': activation, 'learning_rate': learning_rate, 'epochs': epochs, 'hidden_layers': hidden_layers, 'neurons_per_layer': neurons_per_layer}\n",
        "\n",
        "        # After evaluating all hyperparameters for the current fold, store the best for that fold\n",
        "        best_hyperparameters_per_fold.append(best_hyperparameters_for_fold)\n",
        "    return  best_hyperparameters_per_fold\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "global_dict_of_dicts_train = {}\n",
        "global_dict_of_dicts_test={}\n",
        "\n",
        "def save_dict_to_global_store_train(key, input_dict):\n",
        "    \"\"\"\n",
        "    Saves the given dictionary into a global dictionary of dictionaries.\n",
        "    \"\"\"\n",
        "    # Ensure the global dictionary is accessible\n",
        "    global global_dict_of_dicts_train\n",
        "\n",
        "    # Save the input dictionary under the provided key\n",
        "    global_dict_of_dicts_train[key] = input_dict\n",
        "\n",
        "def save_dict_to_global_store_test(key, input_dict):\n",
        "    \"\"\"\n",
        "    Saves the given dictionary into a global dictionary of dictionaries.\n",
        "    \"\"\"\n",
        "    # Ensure the global dictionary is accessible\n",
        "    global global_dict_of_dicts_test\n",
        "\n",
        "    # Save the input dictionary under the provided key\n",
        "    global_dict_of_dicts_test[key] = input_dict\n",
        "\n",
        "def create_mlp_model(input_dim, output_dim, hidden_layers, neurons_per_layer, activation):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Input(shape=(input_dim,)))\n",
        "    for _ in range(hidden_layers):\n",
        "        model.add(tf.keras.layers.Dense(neurons_per_layer, activation=activation))\n",
        "    model.add(tf.keras.layers.Dense(output_dim, activation='linear'))\n",
        "    return model\n",
        "\n",
        "def train_mlp_model(X_train, y_train, X_validation, y_validation, activation, bias_train, bias_validation, learning_rate, epochs, hidden_layers, neurons_per_layer):\n",
        "    model = create_mlp_model(X_train.shape[1], y_train.shape[1], hidden_layers, neurons_per_layer, activation)\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "   # n_outputs = y_train.shape[1]\n",
        "   # output_names = [f'output{i}' for i in range(1, n_outputs)]\n",
        "   #metrics={name: ['mae'] for name in output_names}\n",
        "    sample_weights_train = 1 / bias_train\n",
        "    sample_weights_validation = 1 / bias_validation\n",
        "    model.compile(optimizer=optimizer, loss='mae', metrics=['mae'], weighted_metrics=['mae'])\n",
        "    history = model.fit(X_train, y_train, sample_weight=sample_weights_train, epochs=epochs, validation_data=(X_validation, y_validation, sample_weights_validation), verbose=0)\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_model_per_feature(model, X_test, y_test):\n",
        "    predictions = model.predict(X_test)\n",
        "    # Initialize a dictionary to store MAE for each output with the index as the key\n",
        "    mae_dict = {}\n",
        "    # Calculate MAE for each output and store it in the dictionary\n",
        "    for i in range(y_test.shape[1]):  # y_test is a 2D array with shape (n_samples, n_outputs)\n",
        "        mae = mean_absolute_error(y_test[:, i], predictions[:, i])\n",
        "        mae_dict[i] = mae  # Use output index as the key\n",
        "    mean_mae = np.mean(list(mae_dict.values()))\n",
        "    return mae_dict, mean_mae\n",
        "\n",
        "\n",
        "\n",
        "def plot_box_plots_from_global_dicts(global_dict_of_dicts_train, global_dict_of_dicts_test):\n",
        "    \"\"\"\n",
        "    Generates box plots for each key in each dictionary stored within the provided global dictionaries of dictionaries.\n",
        "    Each key's list of values will be used to generate a separate box plot for both training and testing datasets.\n",
        "    \"\"\"\n",
        "    # Combine the two dictionaries for iteration, labeling them accordingly\n",
        "    combined_dict = {'Train': global_dict_of_dicts_train, 'Test': global_dict_of_dicts_test}\n",
        "\n",
        "    # Iterate through the combined dictionary\n",
        "    for dataset_type, global_dict in combined_dict.items():\n",
        "        # Iterate through each dictionary in the global dictionary\n",
        "        for dict_name, sub_dict in global_dict.items():\n",
        "            # Iterate through each key in the dictionary\n",
        "            for key, values in sub_dict.items():\n",
        "                # Generate a box plot for the list of values\n",
        "                plt.figure(figsize=(6, 4))  # Adjust the figure size as needed\n",
        "                plt.boxplot(values)\n",
        "                plt.title(f'Box plot for {Features[key]} in {dict_name} ({dataset_type})')\n",
        "                plt.ylabel('Values')\n",
        "                plt.xticks([1], Features[key])  # Setting the x-axis to show the key name\n",
        "                plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    for ax, (key, inner_dict) in zip(axs, dict_of_dicts.items()):\n",
        "        # Extracting all lists from the inner dictionary for plotting\n",
        "        data = [value for value in inner_dict.values()]\n",
        "        # Creating box plot for each list\n",
        "        ax.boxplot(data)\n",
        "        ax.set_title(f'Box plot for {key}')\n",
        "        ax.set_xticklabels(inner_dict.keys(), rotation=45, ha='right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def preprocess_data(X_data, diag_array_data, age_data, gndr_data, apoe_data, Time_diff_data):\n",
        "    #print(type(X_data))\n",
        "    # Add age, gender, and apoe as features\n",
        "\n",
        "    #X_data = np.hstack((gndr_data[:, np.newaxis], X_data))\n",
        "    #X_data = np.hstack((apoe_data[:, np.newaxis], X_data))\n",
        "    #X_data = np.hstack((age_data[:, np.newaxis], X_data))\n",
        "\n",
        "    # Add time_diff as input\n",
        "    timedeltas_in_days = Time_diff_data.astype('timedelta64[D]').astype(int)\n",
        "    X_data = np.hstack((timedeltas_in_days[:, np.newaxis], X_data))\n",
        "\n",
        "    # One-hot encode diagnosis features\n",
        "    # encoder = OneHotEncoder()\n",
        "    # diag_array_reshaped = diag_array_data.reshape(-1, 1)\n",
        "    # DX_bl_encoded = encoder.fit_transform(diag_array_reshaped).toarray()\n",
        "    # encoded_data = pd.DataFrame(DX_bl_encoded, columns=encoder.get_feature_names_out(['DX_bl']))\n",
        "    # diag_array_final = pd.concat([pd.DataFrame(diag_array_reshaped), encoded_data], axis=1)\n",
        "    # diag_array_final_np = diag_array_final.to_numpy()\n",
        "    # diagnosis_arr=diag_array_final_np[:, 1:]\n",
        "    # diagnosis_arr = diagnosis_arr.astype(float)\n",
        "    # X_data = np.hstack((X_data, diagnosis_arr))\n",
        "\n",
        "    return X_data\n",
        "\n",
        "\n",
        "\n",
        "#,'selu', 'swish','relu',\n",
        "activations = ['leaky_relu','elu']\n",
        "learning_rates = [0.001]\n",
        "#0.01\n",
        "#400\n",
        "epochs_list = [200,600]\n",
        "hidden_layers_list = [3,4]\n",
        "#2\n",
        "neurons_per_layer_list = [16,32, 64, 128]\n",
        "    #16,32, 64, 128]\n",
        "\n",
        "Inner_Loop_Splits=5\n",
        "\n",
        "Final_hyperparameters_all=[]\n",
        "\n",
        "for i in range(5,6):\n",
        "    key_B = f'train{i}'\n",
        "    Train_Split= dataset_splits[key_B]\n",
        "    print(\"Outer_Loop\")\n",
        "    print(Train_Split.shape)\n",
        "    print(\"Outer_Loop \\n\")\n",
        "\n",
        "    best_hyperparameters = GridSearch(Train_Split, activations, learning_rates, epochs_list, hidden_layers_list, neurons_per_layer_list,Inner_Loop_Splits)\n",
        "    Final_hyperparameters_all.append(best_hyperparameters)\n",
        "\n",
        "#np.array(X_all), np.array(y_all), np.array(rids_all), np.array(diag_array), np.array(datapoints_array), y_col_names, np.array(timediff), np.array(Age_all), np.array(PTGENDER_all), np.array(Apoe_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQTFkHdvKHoI"
      },
      "outputs": [],
      "source": [
        "for i in range(1, len(Final_hyperparameters_all)):\n",
        "  for j in Final_hyperparameters_all[i]:\n",
        "    print(j)\n",
        "#for i in range(1,Outer_Loop_Splits+1):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8a4kNPFC7cj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89134485-eec5-4b63-f817-e96f8cd1e7e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best_models has been pickled and saved to /content/gdrive/MyDrive/Neuro_Tau/Best_models.pkl\n"
          ]
        }
      ],
      "source": [
        "path = '/content/gdrive/MyDrive/Neuro_Tau'\n",
        "os.makedirs(path, exist_ok=True)\n",
        "file_path = os.path.join(path, 'Best_models.pkl')\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(Final_hyperparameters_all, file)\n",
        "\n",
        "print(f'Best_models has been pickled and saved to {file_path}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBplHqRsSmOX",
        "outputId": "9fa9c34a-37a7-4ed8-8624-97fec4f5621b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model parameters: [[{'fold': 1, 'activation': 'leaky_relu', 'learning_rate': 0.001, 'epochs': 600, 'hidden_layers': 4, 'neurons_per_layer': 32}, {'fold': 2, 'activation': 'elu', 'learning_rate': 0.001, 'epochs': 600, 'hidden_layers': 4, 'neurons_per_layer': 128}, {'fold': 3, 'activation': 'leaky_relu', 'learning_rate': 0.001, 'epochs': 600, 'hidden_layers': 4, 'neurons_per_layer': 64}, {'fold': 4, 'activation': 'leaky_relu', 'learning_rate': 0.001, 'epochs': 600, 'hidden_layers': 4, 'neurons_per_layer': 64}, {'fold': 5, 'activation': 'elu', 'learning_rate': 0.001, 'epochs': 600, 'hidden_layers': 4, 'neurons_per_layer': 64}]]\n"
          ]
        }
      ],
      "source": [
        "path = '/content/gdrive/MyDrive/Neuro_Tau'\n",
        "os.makedirs(path, exist_ok=True)\n",
        "# Load the pickle file\n",
        "with open(file_path, 'rb') as file:\n",
        "    Final_hyperparameters_all = pickle.load(file)\n",
        "\n",
        "# Print the loaded parameters to verify\n",
        "print('Loaded model parameters:', Final_hyperparameters_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jy5NT6xO9qAa"
      },
      "outputs": [],
      "source": [
        "for i in range(1, len(Final_hyperparameters_all)):\n",
        "  for j in Final_hyperparameters_all[i]:\n",
        "    print(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu6Tl3lCSHgn"
      },
      "source": [
        "# Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wG9LliQzo9je"
      },
      "outputs": [],
      "source": [
        "# baseline dummy model\n",
        "\n",
        "def dummy_model_per_feature(X_test, y_test):\n",
        "    # Initialize a dictionary to store MAE for each output with the index as the key\n",
        "    mae_dict = {}\n",
        "    # Calculate MAE for each output and store it in the dictionary\n",
        "    for i in range(y_test.shape[1]):  # y_test is a 2D array with shape (n_samples, n_outputs)\n",
        "        mean_mae  = mean_absolute_error(y_test[:, i], X_test[:, i])\n",
        "        mae_dict[i+1] = mean_mae  # Use output index as the key\n",
        "    return mae_dict, mean_mae\n",
        "\n",
        "\n",
        "dummy_mae_dict, dummy_mean_mae= dummy_model_per_feature(X_test, y_test)\n",
        "print(dummy_mae_dict)\n",
        "print(dummy_mean_mae)\n",
        "print(Features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zXDlNNkK7CnL"
      },
      "outputs": [],
      "source": [
        "def dummy_model_per_feature_per_sample(X_test, y_test):\n",
        "    # Initialize a dictionary to store MAE for each output with the index as the key\n",
        "    mae_dict = {}\n",
        "    # Calculate MAE for each output and store it in the dictionary\n",
        "    for i in range(y_test.shape[1]):  # y_test is a 2D array with shape (n_samples, n_outputs)\n",
        "        error  = np.abs(y_test[:, i], X_test[:, i])\n",
        "        mae_dict[i+1] = error  # Use output index as the key\n",
        "    return mae_dict\n",
        "box_plot_dummy_dict = dummy_model_per_feature_per_sample(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ox6d4DcZR-A-"
      },
      "source": [
        "# GGSEG preprocess+ plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdAYzWInN2Nq"
      },
      "outputs": [],
      "source": [
        "pip install ggseg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEsh37kmzOWC"
      },
      "outputs": [],
      "source": [
        "##### OUR DATASET MUST MATCH THE FOLLOWING NAMING FORMAT #######\n",
        "# more info on ggseg https://ggseg.github.io/ggseg/index.html\n",
        "# list of fully applicable regions mentioned in https://github.com/ggseg/python-ggseg/tree/main/ggseg/data/dk , and summarized below\n",
        "roi_list = [\n",
        "    \"NA_left\",\n",
        "    \"NA_right\",\n",
        "    \"bankssts_left\",\n",
        "    \"bankssts_right\",\n",
        "    \"caudalanteriorcingulate_left\",\n",
        "    \"caudalanteriorcingulate_right\",\n",
        "    \"caudalmiddlefrontal_left\",\n",
        "    \"caudalmiddlefrontal_right\",\n",
        "    \"corpuscallosum_left\",\n",
        "    \"corpuscallosum_right\",\n",
        "    \"cuneus_left\",\n",
        "    \"cuneus_right\",\n",
        "    \"entorhinal_left\",\n",
        "    \"entorhinal_right\",\n",
        "    \"fusiform_left\",\n",
        "    \"fusiform_right\",\n",
        "    \"inferiorparietal_left\",\n",
        "    \"inferiorparietal_right\",\n",
        "    \"inferiortemporal_left\",\n",
        "    \"inferiortemporal_right\",\n",
        "    \"insula_left\",\n",
        "    \"insula_right\",\n",
        "    \"isthmuscingulate_left\",\n",
        "    \"isthmuscingulate_right\",\n",
        "    \"lateral_left\",\n",
        "    \"lateral_right\",\n",
        "    \"lateraloccipital_left\",\n",
        "    \"lateraloccipital_right\",\n",
        "    \"lateralorbitofrontal_left\",\n",
        "    \"lateralorbitofrontal_right\",\n",
        "    \"lingual_left\",\n",
        "    \"lingual_right\",\n",
        "    \"medial_left\",\n",
        "    \"medial_right\",\n",
        "    \"medialorbitofrontal_left\",\n",
        "    \"medialorbitofrontal_right\",\n",
        "    \"middletemporal_left\",\n",
        "    \"middletemporal_right\",\n",
        "    \"paracentral_left\",\n",
        "    \"paracentral_right\",\n",
        "    \"parahippocampal_left\",\n",
        "    \"parahippocampal_right\",\n",
        "    \"parsopercularis_left\",\n",
        "    \"parsopercularis_right\",\n",
        "    \"parsorbitalis_left\",\n",
        "    \"parsorbitalis_right\",\n",
        "    \"parstriangularis_left\",\n",
        "    \"parstriangularis_right\",\n",
        "    \"pericalcarine_left\",\n",
        "    \"pericalcarine_right\",\n",
        "    \"postcentral_left\",\n",
        "    \"postcentral_right\",\n",
        "    \"posteriorcingulate_left\",\n",
        "    \"posteriorcingulate_right\",\n",
        "    \"precentral_left\",\n",
        "    \"precentral_right\",\n",
        "    \"precuneus_left\",\n",
        "    \"precuneus_right\",\n",
        "    \"rostralanteriorcingulate_left\",\n",
        "    \"rostralanteriorcingulate_right\",\n",
        "    \"rostralmiddlefrontal_left\",\n",
        "    \"rostralmiddlefrontal_right\",\n",
        "    \"superiorfrontal_left\",\n",
        "    \"superiorfrontal_right\",\n",
        "    \"superiorparietal_left\",\n",
        "    \"superiorparietal_right\",\n",
        "    \"superiortemporal_left\",\n",
        "    \"superiortemporal_right\",\n",
        "    \"supramarginal_left\",\n",
        "    \"supramarginal_right\",\n",
        "    \"transversetemporal_left\",\n",
        "    \"transversetemporal_right\"\n",
        "\n",
        "]\n",
        "print(len(roi_list))\n",
        "\n",
        "# below is a list of subcortical regions supported\n",
        "#full list of subcortical regions is available through this link https://github.com/ggseg/python-ggseg/tree/main/ggseg/data/aseg  and summarized below\n",
        "\n",
        "brain_regions = [\n",
        "    \"3rd-Ventricle\",\n",
        "    \"4th-Ventricle\",\n",
        "    \"Brain-Stem\",\n",
        "    \"CC_Anterior\",\n",
        "    \"CC_Central\",\n",
        "    \"CC_Mid_Anterior\",\n",
        "    \"CC_Mid_Posterior\",\n",
        "    \"CC_Posterior\",\n",
        "    \"Cerebellum-Cortex\",\n",
        "    \"Cerebellum-White-Matter\",\n",
        "    \"Coronal\",\n",
        "    \"Left-Amygdala\",\n",
        "    \"Left-Caudate\",\n",
        "    \"Left-Hippocampus\",\n",
        "    \"Left-Lateral-Ventricle\",\n",
        "    \"Left-Pallidum\",\n",
        "    \"Left-Putamen\",\n",
        "    \"Left-Thalamus\",\n",
        "    \"Left-VentralDC\",\n",
        "    \"Right-Amygdala\",\n",
        "    \"Right-Caudate\",\n",
        "    \"Right-Hippocampus\",\n",
        "    \"Right-Lateral-Ventricle\",\n",
        "    \"Right-Pallidum\",\n",
        "    \"Right-Putamen\",\n",
        "    \"Right-Thalamus\",\n",
        "    \"Right-VentralDC\",\n",
        "    \"Sagittal\"\n",
        "]\n",
        "\n",
        "print(len(brain_regions))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRcX1xqSuPFh"
      },
      "outputs": [],
      "source": [
        "#Proof that our list format matches ggseg format, it should return empty list for uniq , len of transformed_unique_to_processed_list should be 82 which are the num of brain regions we have\n",
        "unique_to_processed_list= [item for item in transformed_unique_to_processed_list if item not in roi_list and item not in brain_regions ]\n",
        "\n",
        "print(\"unique_to_processed_list:\", unique_to_processed_list)\n",
        "print(len(transformed_unique_to_processed_list))\n",
        "print(transformed_unique_to_processed_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DymQkLXVixeS"
      },
      "outputs": [],
      "source": [
        "best_model = 'Hyperparameters: Activation: leaky_relu, LR: 0.001, Epochs: 500, Hidden Layers: 4, Neurons/Layer: 128'\n",
        "\n",
        "best_model='Hyperparameters: Activation: relu, LR: 0.001, Epochs: 800, Hidden Layers: 3, Neurons/Layer: 128'\n",
        "\n",
        "best_model='Hyperparameters: Activation: swish, LR: 0.001, Epochs: 800, Hidden Layers: 4, Neurons/Layer: 128'\n",
        "\n",
        "print(Features)\n",
        "print(len(Features))\n",
        "dictionary_of_best_model_train = {key: value for key, value in global_dict_of_dicts_train.items() if key == best_model}\n",
        "inner_dict = next(iter(dictionary_of_best_model_train.values()))\n",
        "final_dict_train = {i+1: np.mean(values) for i, values in inner_dict.items()}\n",
        "\n",
        "dictionary_of_best_model_test = {key: value for key, value in global_dict_of_dicts_test.items() if key == best_model}\n",
        "inner_dict = next(iter(dictionary_of_best_model_test.values()))\n",
        "final_dict_test = {i+1: np.mean(values) for i, values in inner_dict.items()}\n",
        "\n",
        "def remap_keys(final_dict_test, Features):\n",
        "    \"\"\"\n",
        "    Remaps keys from final_dict_test using the Features list to new keys\n",
        "    \"\"\"\n",
        "    ggseg_dic = {}\n",
        "    for key in final_dict_test.keys():\n",
        "        #print(key)\n",
        "        new_key = Features[int(key) - 1]  # Map old key to new key using Features list\n",
        "        new_value = final_dict_test[key]  # Get the corresponding value\n",
        "        ggseg_dic[new_key] = new_value  # Update ggseg_format_dic_train with the new key-value pair\n",
        "\n",
        "    # Optionally, return the updated dictionary\n",
        "    return ggseg_dic\n",
        "\n",
        "\n",
        "ggseg_format_dic_test = remap_keys(final_dict_test, Features)\n",
        "#ggseg_format_dic_train = remap_keys(final_dict_train, Features)\n",
        "ggseg_format_dic_dummy= remap_keys(dummy_mae_dict, Features)\n",
        "\n",
        "print (ggseg_format_dic_test)\n",
        "#print (ggseg_format_dic_train)\n",
        "print (ggseg_format_dic_dummy)\n",
        "#print(dummy_mae_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_I4CqhoeISBQ"
      },
      "outputs": [],
      "source": [
        "import unittest\n",
        "import ggseg\n",
        "\n",
        "#unify the scale\n",
        "\n",
        "# Combine the values from both dictionaries\n",
        "combined_values = list(ggseg_format_dic_test.values()) + list(ggseg_format_dic_dummy.values())\n",
        "\n",
        "# Find the minimum and maximum values\n",
        "min_value = min(combined_values)\n",
        "max_value = max(combined_values)\n",
        "\n",
        "print(min_value)\n",
        "print(max_value)\n",
        "\n",
        "#min_value = 0\n",
        "#max_value = 0.16\n",
        "\n",
        "ggseg.plot_dk(ggseg_format_dic_test, background='w', edgecolor='k', cmap='hot', title=\"Testing\"+ best_model, ylabel='Error', vminmax=[min_value,max_value])\n",
        "ggseg.plot_aseg(ggseg_format_dic_test, background='k', edgecolor='w', title=\"Testing\" + best_model, bordercolor='gray', cmap='hot', ylabel='error',vminmax=[min_value,max_value])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVwje07w9bPB"
      },
      "outputs": [],
      "source": [
        "ggseg.plot_dk(ggseg_format_dic_dummy, background='w', edgecolor='k', cmap='hot', title=\"Baseline model\", ylabel='Error', vminmax=[min_value,max_value])\n",
        "ggseg.plot_aseg(ggseg_format_dic_dummy, background='k', edgecolor='w', title=\"Baseline model\", bordercolor='gray', cmap='hot', ylabel='error', vminmax=[min_value,max_value])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sH2IYPDf76R4"
      },
      "outputs": [],
      "source": [
        "def remap_keys2(final_dict_test, Features):\n",
        "    \"\"\"\n",
        "    Remaps keys from final_dict_test using the Features list to new keys.\n",
        "    Expects final_dict_test to be a list of values corresponding to Features in order.\n",
        "    \"\"\"\n",
        "    ggseg_dic = {}\n",
        "    for i in range(len(Features)):\n",
        "        new_key = Features[i]  # Use Feature list to map old index to new key\n",
        "        new_value = final_dict_test[i]  # Get the value using string key; default to None if missing\n",
        "        ggseg_dic[new_key] = new_value\n",
        "    return ggseg_dic\n",
        "\n",
        "def process_rid_data(data, rid, Features):\n",
        "    # Extract rows for the given RID\n",
        "    group = data[data['RID'] == rid]\n",
        "\n",
        "    # Select the relevant columns (excluding the last 7 and first 5 columns)\n",
        "    all_tau_features = group.iloc[:, 5:-7]\n",
        "    remapped_dicts = []\n",
        "    # Convert each row to a list of values, then map those values to Features\n",
        "    rows_as_values = all_tau_features.values.tolist()\n",
        "    for row in rows_as_values:\n",
        "      print(row)\n",
        "      remapped_row = remap_keys2(row, Features)\n",
        "      remapped_dicts.append(remapped_row)\n",
        "    return remapped_dicts\n",
        "\n",
        "specific_rid_data = process_rid_data(train_set, 56, Features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMtjXvoA-od-"
      },
      "outputs": [],
      "source": [
        "print (specific_rid_data)\n",
        "type(specific_rid_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQBtslJe-gqb"
      },
      "outputs": [],
      "source": [
        "min_value = None\n",
        "max_value = None\n",
        "\n",
        "for row_dict in specific_rid_data:\n",
        "    for _, value in row_dict.items():\n",
        "        # Update min_value and max_value based on the current value\n",
        "        if min_value is None or value < min_value:\n",
        "            min_value = value\n",
        "        if max_value is None or value > max_value:\n",
        "            max_value = value\n",
        "\n",
        "print(f\"Minimum value across all items: {min_value}\")\n",
        "print(f\"Maximum value across all items: {max_value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hRnIy-3-DVO"
      },
      "outputs": [],
      "source": [
        "# Assuming specific_rid_data is your list of dictionaries\n",
        "for row_dict in specific_rid_data:\n",
        "    # row_dict is now each dictionary within the list\n",
        "    ggseg.plot_dk(row_dict, background='w', edgecolor='k', cmap='hot', title=\"Baseline model\", ylabel='Error', vminmax=[min_value,max_value])\n",
        "    ggseg.plot_aseg(row_dict, background='k', edgecolor='w', title=\"Baseline model\", bordercolor='gray', cmap='hot', ylabel='error', vminmax=[min_value,max_value])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}